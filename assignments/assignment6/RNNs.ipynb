{"cells":[{"cell_type":"markdown","metadata":{"id":"lwK15L4Wshhe"},"source":["# Задание 6: Рекуррентные нейронные сети (RNNs)\n","\n","Это задание адаптиповано из Deep NLP Course at ABBYY (https://github.com/DanAnastasyev/DeepNLP-Course) с разрешения автора - Даниила Анастасьева. Спасибо ему огромное!"]},{"cell_type":"code","source":["!pip install --upgrade pip setuptools wheel"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A0mKGx67ucny","executionInfo":{"status":"ok","timestamp":1683522084072,"user_tz":-420,"elapsed":6822,"user":{"displayName":"Елизавета Егоровна Пришляк","userId":"17629377755238160682"}},"outputId":"25e9f3c8-0d9e-4134-f6e9-03c96cd2334e"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (21.3.1)\n","Collecting pip\n","  Downloading pip-23.1.2-py3-none-any.whl (2.1 MB)\n","     |████████████████████████████████| 2.1 MB 7.6 MB/s            \n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (67.7.2)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (0.40.0)\n","Installing collected packages: pip\n","  Attempting uninstall: pip\n","    Found existing installation: pip 21.3.1\n","    Uninstalling pip-21.3.1:\n","      Successfully uninstalled pip-21.3.1\n","Successfully installed pip-23.1.2\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"]}]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P59NYU98GCb9","executionInfo":{"status":"ok","timestamp":1683522847766,"user_tz":-420,"elapsed":105184,"user":{"displayName":"Елизавета Егоровна Пришляк","userId":"17629377755238160682"}},"outputId":"66ab3ece-752e-489c-d6c3-80c0e8bc267f"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m67.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m96.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["!pip3 -qq install torch==2.0.0\n","!pip3 -qq install bokeh==0.13.0\n","!pip3 -qq install gensim==3.6.0\n","!pip3 -qq install nltk"]},{"cell_type":"code","source":["!pip3 -qq install scikit-learn"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g2gVOXeLxkG0","executionInfo":{"status":"ok","timestamp":1683522981699,"user_tz":-420,"elapsed":4493,"user":{"displayName":"Елизавета Егоровна Пришляк","userId":"17629377755238160682"}},"outputId":"db9cbf51-7dc9-42eb-b2ad-d9f3b6ca176c"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}]},{"cell_type":"code","execution_count":27,"metadata":{"id":"8sVtGHmA9aBM","executionInfo":{"status":"ok","timestamp":1683522992581,"user_tz":-420,"elapsed":633,"user":{"displayName":"Елизавета Егоровна Пришляк","userId":"17629377755238160682"}}},"outputs":[],"source":["import numpy as np\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","\n","if torch.cuda.is_available():\n","    from torch.cuda import FloatTensor, LongTensor\n","else:\n","    from torch import FloatTensor, LongTensor\n","\n","np.random.seed(42)"]},{"cell_type":"markdown","metadata":{"id":"-6CNKM3b4hT1"},"source":["# Рекуррентные нейронные сети (RNNs)"]},{"cell_type":"markdown","metadata":{"id":"O_XkoGNQUeGm"},"source":["## POS Tagging"]},{"cell_type":"markdown","metadata":{"id":"QFEtWrS_4rUs"},"source":["Мы рассмотрим применение рекуррентных сетей к задаче sequence labeling (последняя картинка).\n","\n","![RNN types](http://karpathy.github.io/assets/rnn/diags.jpeg)\n","\n","*From [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)*\n","\n","Самые популярные примеры для такой постановки задачи - Part-of-Speech Tagging и Named Entity Recognition.\n","\n","Мы порешаем сейчас POS Tagging для английского.\n","\n","Будем работать с таким набором тегов:\n","- ADJ - adjective (new, good, high, ...)\n","- ADP - adposition (on, of, at, ...)\n","- ADV - adverb (really, already, still, ...)\n","- CONJ - conjunction (and, or, but, ...)\n","- DET - determiner, article (the, a, some, ...)\n","- NOUN - noun (year, home, costs, ...)\n","- NUM - numeral (twenty-four, fourth, 1991, ...)\n","- PRT - particle (at, on, out, ...)\n","- PRON - pronoun (he, their, her, ...)\n","- VERB - verb (is, say, told, ...)\n","- . - punctuation marks (. , ;)\n","- X - other (ersatz, esprit, dunno, ...)"]},{"cell_type":"markdown","metadata":{"id":"EPIkKdFlHB-X"},"source":["Скачаем данные:"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TiA2dGmgF1rW","executionInfo":{"status":"ok","timestamp":1683522327931,"user_tz":-420,"elapsed":2079,"user":{"displayName":"Елизавета Егоровна Пришляк","userId":"17629377755238160682"}},"outputId":"07462e2a-044c-4993-f520-dfedb5c02043"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package brown to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/brown.zip.\n","[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n","[nltk_data]   Unzipping taggers/universal_tagset.zip.\n"]}],"source":["import nltk\n","from sklearn.model_selection import train_test_split\n","\n","nltk.download('brown')\n","nltk.download('universal_tagset')\n","\n","data = nltk.corpus.brown.tagged_sents(tagset='universal')"]},{"cell_type":"markdown","metadata":{"id":"d93g_swyJA_V"},"source":["Пример размеченного предложения:"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QstS4NO0L97c","executionInfo":{"status":"ok","timestamp":1683523001248,"user_tz":-420,"elapsed":353,"user":{"displayName":"Елизавета Егоровна Пришляк","userId":"17629377755238160682"}},"outputId":"80c96131-cfa2-4fe7-9c11-62c0daeb71e7"},"outputs":[{"output_type":"stream","name":"stdout","text":["The            \tDET\n","Fulton         \tNOUN\n","County         \tNOUN\n","Grand          \tADJ\n","Jury           \tNOUN\n","said           \tVERB\n","Friday         \tNOUN\n","an             \tDET\n","investigation  \tNOUN\n","of             \tADP\n","Atlanta's      \tNOUN\n","recent         \tADJ\n","primary        \tNOUN\n","election       \tNOUN\n","produced       \tVERB\n","``             \t.\n","no             \tDET\n","evidence       \tNOUN\n","''             \t.\n","that           \tADP\n","any            \tDET\n","irregularities \tNOUN\n","took           \tVERB\n","place          \tNOUN\n",".              \t.\n"]}],"source":["for word, tag in data[0]:\n","    print('{:15}\\t{}'.format(word, tag))"]},{"cell_type":"markdown","metadata":{"id":"epdW8u_YXcAv"},"source":["Построим разбиение на train/val/test - наконец-то, всё как у нормальных людей.\n","\n","На train будем учиться, по val - подбирать параметры и делать всякие early stopping, а на test - принимать модель по ее финальному качеству."]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xTai8Ta0lgwL","executionInfo":{"status":"ok","timestamp":1683523027002,"user_tz":-420,"elapsed":21794,"user":{"displayName":"Елизавета Егоровна Пришляк","userId":"17629377755238160682"}},"outputId":"acc63cbb-6f18-446b-9831-a26470351b9b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Words count in train set: 739769\n","Words count in val set: 130954\n","Words count in test set: 290469\n"]}],"source":["train_data, test_data = train_test_split(data, test_size=0.25, random_state=42)\n","train_data, val_data = train_test_split(train_data, test_size=0.15, random_state=42)\n","\n","print('Words count in train set:', sum(len(sent) for sent in train_data))\n","print('Words count in val set:', sum(len(sent) for sent in val_data))\n","print('Words count in test set:', sum(len(sent) for sent in test_data))"]},{"cell_type":"markdown","metadata":{"id":"eChdLNGtXyP0"},"source":["Построим маппинги из слов в индекс и из тега в индекс:\n"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pCjwwDs6Zq9x","executionInfo":{"status":"ok","timestamp":1683523027853,"user_tz":-420,"elapsed":863,"user":{"displayName":"Елизавета Егоровна Пришляк","userId":"17629377755238160682"}},"outputId":"062c8a35-366c-4c41-93ba-7dbbe6195914"},"outputs":[{"output_type":"stream","name":"stdout","text":["Unique words in train = 45441. Tags = {'ADP', 'DET', 'NUM', 'NOUN', 'VERB', 'PRON', '.', 'PRT', 'ADJ', 'ADV', 'X', 'CONJ'}\n"]}],"source":["words = {word for sample in train_data for word, tag in sample}\n","word2ind = {word: ind + 1 for ind, word in enumerate(words)}\n","word2ind['<pad>'] = 0\n","\n","tags = {tag for sample in train_data for word, tag in sample}\n","tag2ind = {tag: ind + 1 for ind, tag in enumerate(tags)}\n","tag2ind['<pad>'] = 0\n","\n","print('Unique words in train = {}. Tags = {}'.format(len(word2ind), tags))"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":445},"id":"URC1B2nvPGFt","executionInfo":{"status":"ok","timestamp":1683523028736,"user_tz":-420,"elapsed":885,"user":{"displayName":"Елизавета Егоровна Пришляк","userId":"17629377755238160682"}},"outputId":"2a8967f0-1455-42af-d600-63c5dc30a464"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1000x500 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","from collections import Counter\n","\n","tag_distribution = Counter(tag for sample in train_data for _, tag in sample)\n","tag_distribution = [tag_distribution[tag] for tag in tags]\n","\n","plt.figure(figsize=(10, 5))\n","\n","bar_width = 0.35\n","plt.bar(np.arange(len(tags)), tag_distribution, bar_width, align='center', alpha=0.5)\n","plt.xticks(np.arange(len(tags)), tags)\n","    \n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"gArQwbzWWkgi"},"source":["## Бейзлайн\n","\n","Какой самый простой теггер можно придумать? Давайте просто запоминать, какие теги самые вероятные для слова (или для последовательности):\n","\n","![tag-context](https://www.nltk.org/images/tag-context.png)  \n","*From [Categorizing and Tagging Words, nltk](https://www.nltk.org/book/ch05.html)*\n","\n","На картинке показано, что для предсказания $t_n$ используются два предыдущих предсказанных тега + текущее слово. По корпусу считаются вероятность для $P(t_n| w_n, t_{n-1}, t_{n-2})$, выбирается тег с максимальной вероятностью.\n","\n","Более аккуратно такая идея реализована в Hidden Markov Models: по тренировочному корпусу вычисляются вероятности $P(w_n| t_n), P(t_n|t_{n-1}, t_{n-2})$ и максимизируется их произведение.\n","\n","Простейший вариант - униграммная модель, учитывающая только слово:"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5rWmSToIaeAo","executionInfo":{"status":"ok","timestamp":1683523033310,"user_tz":-420,"elapsed":4577,"user":{"displayName":"Елизавета Егоровна Пришляк","userId":"17629377755238160682"}},"outputId":"f7c94187-190c-4e09-9435-51f810581a6d"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-32-747c80ba0bc0>:6: DeprecationWarning: \n","  Function evaluate() has been deprecated.  Use accuracy(gold)\n","  instead.\n","  print('Accuracy of unigram tagger = {:.2%}'.format(unigram_tagger.evaluate(test_data)))\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy of unigram tagger = 92.62%\n"]}],"source":["import nltk\n","\n","default_tagger = nltk.DefaultTagger('NN')\n","\n","unigram_tagger = nltk.UnigramTagger(train_data, backoff=default_tagger)\n","print('Accuracy of unigram tagger = {:.2%}'.format(unigram_tagger.evaluate(test_data)))"]},{"cell_type":"markdown","metadata":{"id":"07Ymb_MkbWsF"},"source":["Добавим вероятности переходов:"]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vjz_Rk0bbMyH","executionInfo":{"status":"ok","timestamp":1683523107715,"user_tz":-420,"elapsed":7339,"user":{"displayName":"Елизавета Егоровна Пришляк","userId":"17629377755238160682"}},"outputId":"7ff1b49b-d855-46d5-ea6f-f66ff9e58bf1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy of bigram tagger = 93.42%\n"]}],"source":["bigram_tagger = nltk.BigramTagger(train_data, backoff=unigram_tagger)\n","print('Accuracy of bigram tagger = {:.2%}'.format(bigram_tagger.accuracy(test_data)))"]},{"cell_type":"markdown","metadata":{"id":"uWMw6QHvbaDd"},"source":["Обратите внимание, что `backoff` важен:"]},{"cell_type":"code","execution_count":36,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8XCuxEBVbOY_","executionInfo":{"status":"ok","timestamp":1683523115815,"user_tz":-420,"elapsed":3824,"user":{"displayName":"Елизавета Егоровна Пришляк","userId":"17629377755238160682"}},"outputId":"2a594fb3-3031-4517-dd36-a1b7837e18da"},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy of trigram tagger = 23.33%\n"]}],"source":["trigram_tagger = nltk.TrigramTagger(train_data)\n","print('Accuracy of trigram tagger = {:.2%}'.format(trigram_tagger.accuracy(test_data)))"]},{"cell_type":"markdown","metadata":{"id":"4t3xyYd__8d-"},"source":["## Увеличиваем контекст с рекуррентными сетями\n","\n","Униграмная модель работает на удивление хорошо, но мы же собрались учить сеточки.\n","\n","Омонимия - основная причина, почему униграмная модель плоха:  \n","*“he cashed a check at the **bank**”*  \n","vs  \n","*“he sat on the **bank** of the river”*\n","\n","Поэтому нам очень полезно учитывать контекст при предсказании тега.\n","\n","Воспользуемся LSTM - он умеет работать с контекстом очень даже хорошо:\n","\n","![](https://image.ibb.co/kgmoff/Baseline-Tagger.png)\n","\n","Синим показано выделение фичей из слова, LSTM оранжевенький - он строит эмбеддинги слов с учетом контекста, а дальше зелененькая логистическая регрессия делает предсказания тегов."]},{"cell_type":"code","execution_count":37,"metadata":{"id":"RtRbz1SwgEqc","executionInfo":{"status":"ok","timestamp":1683523123326,"user_tz":-420,"elapsed":2021,"user":{"displayName":"Елизавета Егоровна Пришляк","userId":"17629377755238160682"}}},"outputs":[],"source":["def convert_data(data, word2ind, tag2ind):\n","    X = [[word2ind.get(word, 0) for word, _ in sample] for sample in data]\n","    y = [[tag2ind[tag] for _, tag in sample] for sample in data]\n","    \n","    return X, y\n","\n","X_train, y_train = convert_data(train_data, word2ind, tag2ind)\n","X_val, y_val = convert_data(val_data, word2ind, tag2ind)\n","X_test, y_test = convert_data(test_data, word2ind, tag2ind)"]},{"cell_type":"code","execution_count":38,"metadata":{"id":"DhsTKZalfih6","executionInfo":{"status":"ok","timestamp":1683523123661,"user_tz":-420,"elapsed":2,"user":{"displayName":"Елизавета Егоровна Пришляк","userId":"17629377755238160682"}}},"outputs":[],"source":["def iterate_batches(data, batch_size):\n","    X, y = data\n","    n_samples = len(X)\n","\n","    indices = np.arange(n_samples)\n","    np.random.shuffle(indices)\n","    \n","    for start in range(0, n_samples, batch_size):\n","        end = min(start + batch_size, n_samples)\n","        \n","        batch_indices = indices[start:end]\n","        \n","        max_sent_len = max(len(X[ind]) for ind in batch_indices)\n","        X_batch = np.zeros((max_sent_len, len(batch_indices)))\n","        y_batch = np.zeros((max_sent_len, len(batch_indices)))\n","        \n","        for batch_ind, sample_ind in enumerate(batch_indices):\n","            X_batch[:len(X[sample_ind]), batch_ind] = X[sample_ind]\n","            y_batch[:len(y[sample_ind]), batch_ind] = y[sample_ind]\n","            \n","        yield X_batch, y_batch"]},{"cell_type":"code","execution_count":39,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l4XsRII5kW5x","executionInfo":{"status":"ok","timestamp":1683523126378,"user_tz":-420,"elapsed":316,"user":{"displayName":"Елизавета Егоровна Пришляк","userId":"17629377755238160682"}},"outputId":"d44a0c35-1f72-4a05-ef79-c401ae399d44"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((32, 4), (32, 4))"]},"metadata":{},"execution_count":39}],"source":["X_batch, y_batch = next(iterate_batches((X_train, y_train), 4))\n","\n","X_batch.shape, y_batch.shape"]},{"cell_type":"markdown","metadata":{"id":"C5I9E9P6eFYv"},"source":["**Задание** Реализуйте `LSTMTagger`:"]},{"cell_type":"code","execution_count":42,"metadata":{"id":"WVEHju54d68T","executionInfo":{"status":"ok","timestamp":1683523295905,"user_tz":-420,"elapsed":351,"user":{"displayName":"Елизавета Егоровна Пришляк","userId":"17629377755238160682"}}},"outputs":[],"source":["class LSTMTagger(nn.Module):\n","    def __init__(self, vocab_size, tagset_size, word_emb_dim=100, lstm_hidden_dim=128, lstm_layers_count=1):\n","        super().__init__()\n","        self.target_size = tagset_size\n","        self.lstm_layers_count = lstm_layers_count\n","        self.lstm_hidden_dim = lstm_hidden_dim\n","        self.fully_connected = nn.Linear(lstm_hidden_dim, tagset_size)\n","        self.embedding = nn.Embedding(vocab_size, word_emb_dim)\n","        self.lstm = nn.LSTM(word_emb_dim, lstm_hidden_dim, lstm_layers_count)\n","\n","    def forward(self, inputs):\n","        embedded_in = self.embedding(inputs)\n","        lstm_out, _ = self.lstm(embedded_in)\n","        lstm_out = self.fully_connected(lstm_out)\n","        return lstm_out"]},{"cell_type":"markdown","metadata":{"id":"q_HA8zyheYGH"},"source":["**Задание** Научитесь считать accuracy и loss (а заодно проверьте, что модель работает)"]},{"cell_type":"code","execution_count":43,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jbrxsZ2mehWB","executionInfo":{"status":"ok","timestamp":1683523376527,"user_tz":-420,"elapsed":338,"user":{"displayName":"Елизавета Егоровна Пришляк","userId":"17629377755238160682"}},"outputId":"b0a56bd4-4f54-4636-cec3-6d6f5860a5c2"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(6, 92)"]},"metadata":{},"execution_count":43}],"source":["model = LSTMTagger(\n","    vocab_size=len(word2ind),\n","    tagset_size=len(tag2ind)\n",")\n","\n","X_batch, y_batch = torch.LongTensor(X_batch), torch.LongTensor(y_batch)\n","\n","logits = model(X_batch)\n","\n","def calculate_accuracy(prediction, ground_truth):\n","    _, indices = torch.max(prediction, -1)\n","    total = torch.sum(ground_truth > 0).item()\n","    correct = torch.sum((indices == ground_truth) * (ground_truth > 0)).item()\n","    return correct, total\n","\n","calculate_accuracy(logits, y_batch)"]},{"cell_type":"code","execution_count":44,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GMUyUm1hgpe3","executionInfo":{"status":"ok","timestamp":1683523409035,"user_tz":-420,"elapsed":3,"user":{"displayName":"Елизавета Егоровна Пришляк","userId":"17629377755238160682"}},"outputId":"531b9a2b-400d-4dac-d4a6-4d85c923b804"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(2.5911, grad_fn=<NllLossBackward0>)"]},"metadata":{},"execution_count":44}],"source":["criterion = nn.CrossEntropyLoss()\n","criterion(logits.reshape((-1,len(tag2ind))), y_batch.view(-1))"]},{"cell_type":"markdown","metadata":{"id":"nSgV3NPUpcjH"},"source":["**Задание** Вставьте эти вычисление в функцию:"]},{"cell_type":"code","execution_count":46,"metadata":{"id":"FprPQ0gllo7b","executionInfo":{"status":"ok","timestamp":1683524843215,"user_tz":-420,"elapsed":381,"user":{"displayName":"Елизавета Егоровна Пришляк","userId":"17629377755238160682"}}},"outputs":[],"source":["import math\n","from tqdm import tqdm\n","\n","\n","def do_epoch(model, criterion, data, batch_size, optimizer=None, name=None):\n","    epoch_loss = 0\n","    correct_count = 0\n","    sum_count = 0\n","    \n","    is_train = not optimizer is None\n","    name = name or ''\n","    model.train(is_train)\n","    \n","    batches_count = math.ceil(len(data[0]) / batch_size)\n","    \n","    with torch.autograd.set_grad_enabled(is_train):\n","        with tqdm(total=batches_count) as progress_bar:\n","            for i, (X_batch, y_batch) in enumerate(iterate_batches(data, batch_size)):\n","                X_batch, y_batch = LongTensor(X_batch), LongTensor(y_batch)\n","                logits = model(X_batch)\n","\n","                loss = criterion(logits.reshape((-1, len(tag2ind))), y_batch.view(-1))\n","\n","                epoch_loss += loss.item()\n","\n","                if optimizer:\n","                    optimizer.zero_grad()\n","                    loss.backward()\n","                    optimizer.step()\n","\n","                cur_correct_count, cur_sum_count = calculate_accuracy(logits, y_batch)\n","\n","                correct_count += cur_correct_count\n","                sum_count += cur_sum_count\n","\n","                progress_bar.update()\n","                progress_bar.set_description('{:>5s} Loss = {:.5f}, Accuracy = {:.2%}'.format(\n","                    name, loss.item(), cur_correct_count / cur_sum_count)\n","                )\n","                \n","            progress_bar.set_description('{:>5s} Loss = {:.5f}, Accuracy = {:.2%}'.format(\n","                name, epoch_loss / batches_count, correct_count / sum_count)\n","            )\n","\n","    return epoch_loss / batches_count, correct_count / sum_count\n","\n","\n","def fit(model, criterion, optimizer, train_data, epochs_count=1, batch_size=32,\n","        val_data=None, val_batch_size=None):\n","        \n","    if not val_data is None and val_batch_size is None:\n","        val_batch_size = batch_size\n","        \n","    for epoch in range(epochs_count):\n","        name_prefix = '[{} / {}] '.format(epoch + 1, epochs_count)\n","        train_loss, train_acc = do_epoch(model, criterion, train_data, batch_size, optimizer, name_prefix + 'Train:')\n","        \n","        if not val_data is None:\n","            val_loss, val_acc = do_epoch(model, criterion, val_data, val_batch_size, None, name_prefix + '  Val:')"]},{"cell_type":"code","execution_count":47,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Pqfbeh1ltEYa","executionInfo":{"status":"ok","timestamp":1683525180938,"user_tz":-420,"elapsed":322364,"user":{"displayName":"Елизавета Егоровна Пришляк","userId":"17629377755238160682"}},"outputId":"be9e2dee-0169-4839-8ed9-343b85217afe"},"outputs":[{"output_type":"stream","name":"stderr","text":["[1 / 50] Train: Loss = 0.31543, Accuracy = 71.51%: 100%|██████████| 572/572 [00:05<00:00, 96.75it/s] \n","[1 / 50]   Val: Loss = 0.10635, Accuracy = 84.87%: 100%|██████████| 13/13 [00:00<00:00, 88.82it/s]\n","[2 / 50] Train: Loss = 0.10149, Accuracy = 89.92%: 100%|██████████| 572/572 [00:05<00:00, 107.25it/s]\n","[2 / 50]   Val: Loss = 0.07584, Accuracy = 89.37%: 100%|██████████| 13/13 [00:00<00:00, 91.38it/s]\n","[3 / 50] Train: Loss = 0.06792, Accuracy = 93.19%: 100%|██████████| 572/572 [00:06<00:00, 92.58it/s]\n","[3 / 50]   Val: Loss = 0.06615, Accuracy = 91.20%: 100%|██████████| 13/13 [00:00<00:00, 77.12it/s]\n","[4 / 50] Train: Loss = 0.05075, Accuracy = 94.83%: 100%|██████████| 572/572 [00:05<00:00, 105.23it/s]\n","[4 / 50]   Val: Loss = 0.06560, Accuracy = 92.11%: 100%|██████████| 13/13 [00:00<00:00, 87.67it/s]\n","[5 / 50] Train: Loss = 0.04065, Accuracy = 95.83%: 100%|██████████| 572/572 [00:06<00:00, 87.28it/s]\n","[5 / 50]   Val: Loss = 0.06552, Accuracy = 92.69%: 100%|██████████| 13/13 [00:00<00:00, 72.73it/s]\n","[6 / 50] Train: Loss = 0.03302, Accuracy = 96.57%: 100%|██████████| 572/572 [00:06<00:00, 85.86it/s]\n","[6 / 50]   Val: Loss = 0.06158, Accuracy = 93.07%: 100%|██████████| 13/13 [00:00<00:00, 86.37it/s]\n","[7 / 50] Train: Loss = 0.02742, Accuracy = 97.16%: 100%|██████████| 572/572 [00:05<00:00, 107.50it/s]\n","[7 / 50]   Val: Loss = 0.06376, Accuracy = 93.15%: 100%|██████████| 13/13 [00:00<00:00, 85.41it/s]\n","[8 / 50] Train: Loss = 0.02258, Accuracy = 97.64%: 100%|██████████| 572/572 [00:05<00:00, 97.33it/s]\n","[8 / 50]   Val: Loss = 0.06490, Accuracy = 93.31%: 100%|██████████| 13/13 [00:00<00:00, 74.96it/s]\n","[9 / 50] Train: Loss = 0.01881, Accuracy = 98.02%: 100%|██████████| 572/572 [00:06<00:00, 85.66it/s] \n","[9 / 50]   Val: Loss = 0.07233, Accuracy = 93.34%: 100%|██████████| 13/13 [00:00<00:00, 92.43it/s]\n","[10 / 50] Train: Loss = 0.01565, Accuracy = 98.37%: 100%|██████████| 572/572 [00:05<00:00, 106.53it/s]\n","[10 / 50]   Val: Loss = 0.07548, Accuracy = 93.34%: 100%|██████████| 13/13 [00:00<00:00, 75.85it/s]\n","[11 / 50] Train: Loss = 0.01291, Accuracy = 98.68%: 100%|██████████| 572/572 [00:06<00:00, 89.75it/s] \n","[11 / 50]   Val: Loss = 0.06938, Accuracy = 93.29%: 100%|██████████| 13/13 [00:00<00:00, 80.72it/s]\n","[12 / 50] Train: Loss = 0.01072, Accuracy = 98.92%: 100%|██████████| 572/572 [00:05<00:00, 106.33it/s]\n","[12 / 50]   Val: Loss = 0.07789, Accuracy = 93.32%: 100%|██████████| 13/13 [00:00<00:00, 89.68it/s]\n","[13 / 50] Train: Loss = 0.00870, Accuracy = 99.13%: 100%|██████████| 572/572 [00:05<00:00, 100.80it/s]\n","[13 / 50]   Val: Loss = 0.07441, Accuracy = 93.19%: 100%|██████████| 13/13 [00:00<00:00, 79.25it/s]\n","[14 / 50] Train: Loss = 0.00710, Accuracy = 99.31%: 100%|██████████| 572/572 [00:06<00:00, 94.70it/s] \n","[14 / 50]   Val: Loss = 0.07943, Accuracy = 93.10%: 100%|██████████| 13/13 [00:00<00:00, 84.50it/s]\n","[15 / 50] Train: Loss = 0.00578, Accuracy = 99.45%: 100%|██████████| 572/572 [00:07<00:00, 78.24it/s]\n","[15 / 50]   Val: Loss = 0.08643, Accuracy = 93.13%: 100%|██████████| 13/13 [00:00<00:00, 68.45it/s]\n","[16 / 50] Train: Loss = 0.00465, Accuracy = 99.57%: 100%|██████████| 572/572 [00:08<00:00, 69.59it/s] \n","[16 / 50]   Val: Loss = 0.08580, Accuracy = 93.15%: 100%|██████████| 13/13 [00:00<00:00, 86.39it/s]\n","[17 / 50] Train: Loss = 0.00388, Accuracy = 99.65%: 100%|██████████| 572/572 [00:05<00:00, 105.66it/s]\n","[17 / 50]   Val: Loss = 0.09138, Accuracy = 93.09%: 100%|██████████| 13/13 [00:00<00:00, 86.41it/s]\n","[18 / 50] Train: Loss = 0.00322, Accuracy = 99.71%: 100%|██████████| 572/572 [00:06<00:00, 93.94it/s]\n","[18 / 50]   Val: Loss = 0.10205, Accuracy = 93.09%: 100%|██████████| 13/13 [00:00<00:00, 69.36it/s]\n","[19 / 50] Train: Loss = 0.00276, Accuracy = 99.75%: 100%|██████████| 572/572 [00:06<00:00, 84.58it/s] \n","[19 / 50]   Val: Loss = 0.10052, Accuracy = 93.03%: 100%|██████████| 13/13 [00:00<00:00, 82.81it/s]\n","[20 / 50] Train: Loss = 0.00242, Accuracy = 99.78%: 100%|██████████| 572/572 [00:05<00:00, 96.11it/s]\n","[20 / 50]   Val: Loss = 0.10715, Accuracy = 92.98%: 100%|██████████| 13/13 [00:00<00:00, 88.49it/s]\n","[21 / 50] Train: Loss = 0.00233, Accuracy = 99.79%: 100%|██████████| 572/572 [00:06<00:00, 89.15it/s]\n","[21 / 50]   Val: Loss = 0.10481, Accuracy = 92.98%: 100%|██████████| 13/13 [00:00<00:00, 80.53it/s]\n","[22 / 50] Train: Loss = 0.00207, Accuracy = 99.80%: 100%|██████████| 572/572 [00:05<00:00, 103.59it/s]\n","[22 / 50]   Val: Loss = 0.11476, Accuracy = 93.01%: 100%|██████████| 13/13 [00:00<00:00, 85.90it/s]\n","[23 / 50] Train: Loss = 0.00186, Accuracy = 99.82%: 100%|██████████| 572/572 [00:05<00:00, 99.79it/s]\n","[23 / 50]   Val: Loss = 0.11144, Accuracy = 93.02%: 100%|██████████| 13/13 [00:00<00:00, 82.37it/s]\n","[24 / 50] Train: Loss = 0.00180, Accuracy = 99.82%: 100%|██████████| 572/572 [00:06<00:00, 90.85it/s] \n","[24 / 50]   Val: Loss = 0.12410, Accuracy = 92.99%: 100%|██████████| 13/13 [00:00<00:00, 90.43it/s]\n","[25 / 50] Train: Loss = 0.00212, Accuracy = 99.79%: 100%|██████████| 572/572 [00:05<00:00, 104.25it/s]\n","[25 / 50]   Val: Loss = 0.11457, Accuracy = 92.98%: 100%|██████████| 13/13 [00:00<00:00, 89.22it/s]\n","[26 / 50] Train: Loss = 0.00189, Accuracy = 99.81%: 100%|██████████| 572/572 [00:05<00:00, 96.41it/s]\n","[26 / 50]   Val: Loss = 0.12019, Accuracy = 92.96%: 100%|██████████| 13/13 [00:00<00:00, 64.89it/s]\n","[27 / 50] Train: Loss = 0.00159, Accuracy = 99.83%: 100%|██████████| 572/572 [00:05<00:00, 96.27it/s] \n","[27 / 50]   Val: Loss = 0.12600, Accuracy = 93.01%: 100%|██████████| 13/13 [00:00<00:00, 88.20it/s]\n","[28 / 50] Train: Loss = 0.00147, Accuracy = 99.84%: 100%|██████████| 572/572 [00:05<00:00, 104.34it/s]\n","[28 / 50]   Val: Loss = 0.12159, Accuracy = 93.01%: 100%|██████████| 13/13 [00:00<00:00, 84.82it/s]\n","[29 / 50] Train: Loss = 0.00151, Accuracy = 99.84%: 100%|██████████| 572/572 [00:06<00:00, 93.52it/s]\n","[29 / 50]   Val: Loss = 0.12839, Accuracy = 92.99%: 100%|██████████| 13/13 [00:00<00:00, 80.48it/s]\n","[30 / 50] Train: Loss = 0.00179, Accuracy = 99.81%: 100%|██████████| 572/572 [00:05<00:00, 101.36it/s]\n","[30 / 50]   Val: Loss = 0.13198, Accuracy = 92.92%: 100%|██████████| 13/13 [00:00<00:00, 83.99it/s]\n","[31 / 50] Train: Loss = 0.00210, Accuracy = 99.77%: 100%|██████████| 572/572 [00:05<00:00, 100.53it/s]\n","[31 / 50]   Val: Loss = 0.13300, Accuracy = 92.94%: 100%|██████████| 13/13 [00:00<00:00, 80.99it/s]\n","[32 / 50] Train: Loss = 0.00153, Accuracy = 99.83%: 100%|██████████| 572/572 [00:06<00:00, 89.92it/s]\n","[32 / 50]   Val: Loss = 0.12934, Accuracy = 93.09%: 100%|██████████| 13/13 [00:00<00:00, 80.59it/s]\n","[33 / 50] Train: Loss = 0.00138, Accuracy = 99.84%: 100%|██████████| 572/572 [00:05<00:00, 103.07it/s]\n","[33 / 50]   Val: Loss = 0.13707, Accuracy = 93.00%: 100%|██████████| 13/13 [00:00<00:00, 86.53it/s]\n","[34 / 50] Train: Loss = 0.00134, Accuracy = 99.84%: 100%|██████████| 572/572 [00:06<00:00, 82.57it/s]\n","[34 / 50]   Val: Loss = 0.14528, Accuracy = 93.03%: 100%|██████████| 13/13 [00:00<00:00, 53.75it/s]\n","[35 / 50] Train: Loss = 0.00142, Accuracy = 99.84%: 100%|██████████| 572/572 [00:07<00:00, 78.92it/s] \n","[35 / 50]   Val: Loss = 0.13219, Accuracy = 93.00%: 100%|██████████| 13/13 [00:00<00:00, 81.30it/s]\n","[36 / 50] Train: Loss = 0.00147, Accuracy = 99.83%: 100%|██████████| 572/572 [00:06<00:00, 93.10it/s]\n","[36 / 50]   Val: Loss = 0.15049, Accuracy = 93.00%: 100%|██████████| 13/13 [00:00<00:00, 46.14it/s]\n","[37 / 50] Train: Loss = 0.00205, Accuracy = 99.77%: 100%|██████████| 572/572 [00:06<00:00, 85.32it/s]\n","[37 / 50]   Val: Loss = 0.14771, Accuracy = 93.01%: 100%|██████████| 13/13 [00:00<00:00, 85.99it/s]\n","[38 / 50] Train: Loss = 0.00164, Accuracy = 99.82%: 100%|██████████| 572/572 [00:06<00:00, 88.98it/s]\n","[38 / 50]   Val: Loss = 0.13633, Accuracy = 92.97%: 100%|██████████| 13/13 [00:00<00:00, 76.75it/s]\n","[39 / 50] Train: Loss = 0.00133, Accuracy = 99.84%: 100%|██████████| 572/572 [00:07<00:00, 76.53it/s]\n","[39 / 50]   Val: Loss = 0.16362, Accuracy = 92.99%: 100%|██████████| 13/13 [00:00<00:00, 64.84it/s]\n","[40 / 50] Train: Loss = 0.00129, Accuracy = 99.85%: 100%|██████████| 572/572 [00:06<00:00, 94.77it/s]\n","[40 / 50]   Val: Loss = 0.15640, Accuracy = 92.97%: 100%|██████████| 13/13 [00:00<00:00, 87.58it/s]\n","[41 / 50] Train: Loss = 0.00129, Accuracy = 99.85%: 100%|██████████| 572/572 [00:05<00:00, 101.25it/s]\n","[41 / 50]   Val: Loss = 0.15249, Accuracy = 93.00%: 100%|██████████| 13/13 [00:00<00:00, 84.72it/s]\n","[42 / 50] Train: Loss = 0.00132, Accuracy = 99.84%: 100%|██████████| 572/572 [00:06<00:00, 89.31it/s]\n","[42 / 50]   Val: Loss = 0.17017, Accuracy = 92.98%: 100%|██████████| 13/13 [00:00<00:00, 72.52it/s]\n","[43 / 50] Train: Loss = 0.00130, Accuracy = 99.84%: 100%|██████████| 572/572 [00:06<00:00, 94.27it/s]\n","[43 / 50]   Val: Loss = 0.15977, Accuracy = 93.06%: 100%|██████████| 13/13 [00:00<00:00, 84.42it/s]\n","[44 / 50] Train: Loss = 0.00140, Accuracy = 99.84%: 100%|██████████| 572/572 [00:05<00:00, 98.76it/s]\n","[44 / 50]   Val: Loss = 0.15883, Accuracy = 92.83%: 100%|██████████| 13/13 [00:00<00:00, 82.84it/s]\n","[45 / 50] Train: Loss = 0.00252, Accuracy = 99.72%: 100%|██████████| 572/572 [00:06<00:00, 89.27it/s]\n","[45 / 50]   Val: Loss = 0.15445, Accuracy = 92.90%: 100%|██████████| 13/13 [00:00<00:00, 85.48it/s]\n","[46 / 50] Train: Loss = 0.00138, Accuracy = 99.83%: 100%|██████████| 572/572 [00:05<00:00, 102.11it/s]\n","[46 / 50]   Val: Loss = 0.16041, Accuracy = 92.99%: 100%|██████████| 13/13 [00:00<00:00, 84.52it/s]\n","[47 / 50] Train: Loss = 0.00123, Accuracy = 99.85%: 100%|██████████| 572/572 [00:06<00:00, 95.29it/s]\n","[47 / 50]   Val: Loss = 0.15507, Accuracy = 93.08%: 100%|██████████| 13/13 [00:00<00:00, 77.79it/s]\n","[48 / 50] Train: Loss = 0.00121, Accuracy = 99.85%: 100%|██████████| 572/572 [00:06<00:00, 92.82it/s] \n","[48 / 50]   Val: Loss = 0.16207, Accuracy = 93.07%: 100%|██████████| 13/13 [00:00<00:00, 82.13it/s]\n","[49 / 50] Train: Loss = 0.00123, Accuracy = 99.85%: 100%|██████████| 572/572 [00:05<00:00, 101.62it/s]\n","[49 / 50]   Val: Loss = 0.16296, Accuracy = 93.00%: 100%|██████████| 13/13 [00:00<00:00, 83.87it/s]\n","[50 / 50] Train: Loss = 0.00122, Accuracy = 99.85%: 100%|██████████| 572/572 [00:06<00:00, 92.22it/s]\n","[50 / 50]   Val: Loss = 0.17009, Accuracy = 93.00%: 100%|██████████| 13/13 [00:00<00:00, 73.23it/s]\n"]}],"source":["model = LSTMTagger(\n","    vocab_size=len(word2ind),\n","    tagset_size=len(tag2ind)\n",").cuda()\n","\n","criterion = nn.CrossEntropyLoss().cuda()\n","optimizer = optim.Adam(model.parameters())\n","\n","fit(model, criterion, optimizer, train_data=(X_train, y_train), epochs_count=50,\n","    batch_size=64, val_data=(X_val, y_val), val_batch_size=512)"]},{"cell_type":"markdown","metadata":{"id":"m0qGetIhfUE5"},"source":["### Masking\n","\n","**Задание** Проверьте себя - не считаете ли вы потери и accuracy на паддингах - очень легко получить высокое качество за счет этого.\n","\n","У функции потерь есть параметр `ignore_index`, для таких целей. Для accuracy нужно использовать маскинг - умножение на маску из нулей и единиц, где нули на позициях паддингов (а потом усреднение по ненулевым позициям в маске)."]},{"cell_type":"markdown","metadata":{"id":"nAfV2dEOfHo5"},"source":["**Задание** Посчитайте качество модели на тесте. Ожидается результат лучше бейзлайна!"]},{"cell_type":"code","execution_count":48,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"98wr38_rw55D","executionInfo":{"status":"ok","timestamp":1683525180938,"user_tz":-420,"elapsed":23,"user":{"displayName":"Елизавета Егоровна Пришляк","userId":"17629377755238160682"}},"outputId":"e27409f2-6875-4c4c-b9ad-9f08579e3542"},"outputs":[{"output_type":"stream","name":"stderr","text":["      Loss = 0.17189, Accuracy = 93.07%: 100%|██████████| 28/28 [00:00<00:00, 71.95it/s]\n"]}],"source":["loss, acc = do_epoch(model, criterion, (X_test, y_test), 512)"]},{"cell_type":"code","source":["def evaluate_model(model, data, batch_size):\n","    loss, acc = do_epoch(model, criterion, data, batch_size)"],"metadata":{"id":"06Dd4Fsm6IYi","executionInfo":{"status":"ok","timestamp":1683525180938,"user_tz":-420,"elapsed":6,"user":{"displayName":"Елизавета Егоровна Пришляк","userId":"17629377755238160682"}}},"execution_count":49,"outputs":[]},{"cell_type":"code","source":["evaluate_model(model, data=(X_test, y_test), batch_size=512)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dT24ZiLD6K8C","executionInfo":{"status":"ok","timestamp":1683525181397,"user_tz":-420,"elapsed":465,"user":{"displayName":"Елизавета Егоровна Пришляк","userId":"17629377755238160682"}},"outputId":"c7467a0c-6255-410c-bec7-21306c77b8a5"},"execution_count":50,"outputs":[{"output_type":"stream","name":"stderr","text":["      Loss = 0.17514, Accuracy = 93.07%: 100%|██████████| 28/28 [00:00<00:00, 76.90it/s]\n"]}]},{"cell_type":"markdown","metadata":{"id":"PXUTSFaEHbDG"},"source":["### Bidirectional LSTM\n","\n","Благодаря BiLSTM можно использовать сразу оба контеста при предсказании тега слова. Т.е. для каждого токена $w_i$ forward LSTM будет выдавать представление $\\mathbf{f_i} \\sim (w_1, \\ldots, w_i)$ - построенное по всему левому контексту - и $\\mathbf{b_i} \\sim (w_n, \\ldots, w_i)$ - представление правого контекста. Их конкатенация автоматически захватит весь доступный контекст слова: $\\mathbf{h_i} = [\\mathbf{f_i}, \\mathbf{b_i}] \\sim (w_1, \\ldots, w_n)$.\n","\n","![BiLSTM](https://www.researchgate.net/profile/Wang_Ling/publication/280912217/figure/fig2/AS:391505383575555@1470353565299/Illustration-of-our-neural-network-for-POS-tagging.png)  \n","*From [Finding Function in Form: Compositional Character Models for Open Vocabulary Word Representation](https://arxiv.org/abs/1508.02096)*\n","\n","**Задание** Добавьте Bidirectional LSTM."]},{"cell_type":"code","execution_count":51,"metadata":{"id":"i8o8-bPishhr","executionInfo":{"status":"ok","timestamp":1683525181397,"user_tz":-420,"elapsed":6,"user":{"displayName":"Елизавета Егоровна Пришляк","userId":"17629377755238160682"}}},"outputs":[],"source":["class BiLSTMTagger(nn.Module):\n","    def __init__(self, vocab_size, tagset_size, word_emb_dim=100, lstm_hidden_dim=128, lstm_layers_count=1):\n","        super().__init__()\n","        self.embedding = nn.Embedding(vocab_size, word_emb_dim)\n","        self.lstm = nn.LSTM(word_emb_dim, lstm_hidden_dim, num_layers=lstm_layers_count, bidirectional=True)\n","        self.fully_connected = nn.Linear(lstm_hidden_dim * 2, tagset_size)\n","\n","    def forward(self, inputs):\n","        embedding_in = self.embedding(inputs)\n","        lstm_out, _ = self.lstm(embedding_in)\n","        return self.fully_connected(lstm_out)"]},{"cell_type":"code","source":["model = BiLSTMTagger(\n","    vocab_size=len(word2ind),\n","    tagset_size=len(tag2ind)\n",").cuda()\n","\n","criterion = nn.CrossEntropyLoss().cuda()\n","optimizer = optim.Adam(model.parameters())"],"metadata":{"id":"QoUNm6Bi6jqf","executionInfo":{"status":"ok","timestamp":1683525181398,"user_tz":-420,"elapsed":6,"user":{"displayName":"Елизавета Егоровна Пришляк","userId":"17629377755238160682"}}},"execution_count":52,"outputs":[]},{"cell_type":"code","source":["fit(model, criterion, optimizer, train_data=(X_train, y_train), epochs_count=50,\n","    batch_size=64, val_data=(X_val, y_val), val_batch_size=512)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t2XhPtiR6mwU","executionInfo":{"status":"ok","timestamp":1683525573537,"user_tz":-420,"elapsed":392145,"user":{"displayName":"Елизавета Егоровна Пришляк","userId":"17629377755238160682"}},"outputId":"fd82d83b-2534-483f-aea2-a6091d734385"},"execution_count":53,"outputs":[{"output_type":"stream","name":"stderr","text":["[1 / 50] Train: Loss = 0.25762, Accuracy = 76.51%: 100%|██████████| 572/572 [00:07<00:00, 79.21it/s]\n","[1 / 50]   Val: Loss = 0.06880, Accuracy = 89.65%: 100%|██████████| 13/13 [00:00<00:00, 62.88it/s]\n","[2 / 50] Train: Loss = 0.07602, Accuracy = 92.65%: 100%|██████████| 572/572 [00:07<00:00, 77.54it/s]\n","[2 / 50]   Val: Loss = 0.04966, Accuracy = 93.53%: 100%|██████████| 13/13 [00:00<00:00, 60.40it/s]\n","[3 / 50] Train: Loss = 0.04881, Accuracy = 95.34%: 100%|██████████| 572/572 [00:07<00:00, 80.61it/s]\n","[3 / 50]   Val: Loss = 0.03779, Accuracy = 94.83%: 100%|██████████| 13/13 [00:00<00:00, 63.52it/s]\n","[4 / 50] Train: Loss = 0.03457, Accuracy = 96.74%: 100%|██████████| 572/572 [00:08<00:00, 69.46it/s]\n","[4 / 50]   Val: Loss = 0.03349, Accuracy = 95.51%: 100%|██████████| 13/13 [00:00<00:00, 54.71it/s]\n","[5 / 50] Train: Loss = 0.02502, Accuracy = 97.64%: 100%|██████████| 572/572 [00:07<00:00, 80.54it/s]\n","[5 / 50]   Val: Loss = 0.03438, Accuracy = 95.93%: 100%|██████████| 13/13 [00:00<00:00, 66.60it/s]\n","[6 / 50] Train: Loss = 0.01847, Accuracy = 98.32%: 100%|██████████| 572/572 [00:07<00:00, 80.86it/s]\n","[6 / 50]   Val: Loss = 0.03304, Accuracy = 96.10%: 100%|██████████| 13/13 [00:00<00:00, 60.61it/s]\n","[7 / 50] Train: Loss = 0.01335, Accuracy = 98.81%: 100%|██████████| 572/572 [00:07<00:00, 77.04it/s]\n","[7 / 50]   Val: Loss = 0.03238, Accuracy = 96.11%: 100%|██████████| 13/13 [00:00<00:00, 65.52it/s]\n","[8 / 50] Train: Loss = 0.00929, Accuracy = 99.19%: 100%|██████████| 572/572 [00:07<00:00, 76.52it/s]\n","[8 / 50]   Val: Loss = 0.03369, Accuracy = 96.16%: 100%|██████████| 13/13 [00:00<00:00, 59.49it/s]\n","[9 / 50] Train: Loss = 0.00630, Accuracy = 99.47%: 100%|██████████| 572/572 [00:09<00:00, 61.95it/s]\n","[9 / 50]   Val: Loss = 0.03796, Accuracy = 96.16%: 100%|██████████| 13/13 [00:00<00:00, 64.00it/s]\n","[10 / 50] Train: Loss = 0.00422, Accuracy = 99.68%: 100%|██████████| 572/572 [00:08<00:00, 66.88it/s]\n","[10 / 50]   Val: Loss = 0.03713, Accuracy = 96.14%: 100%|██████████| 13/13 [00:00<00:00, 54.64it/s]\n","[11 / 50] Train: Loss = 0.00274, Accuracy = 99.81%: 100%|██████████| 572/572 [00:07<00:00, 77.76it/s]\n","[11 / 50]   Val: Loss = 0.03999, Accuracy = 96.19%: 100%|██████████| 13/13 [00:00<00:00, 65.09it/s]\n","[12 / 50] Train: Loss = 0.00178, Accuracy = 99.89%: 100%|██████████| 572/572 [00:07<00:00, 75.79it/s]\n","[12 / 50]   Val: Loss = 0.04310, Accuracy = 96.25%: 100%|██████████| 13/13 [00:00<00:00, 32.31it/s]\n","[13 / 50] Train: Loss = 0.00107, Accuracy = 99.95%: 100%|██████████| 572/572 [00:09<00:00, 58.07it/s]\n","[13 / 50]   Val: Loss = 0.04468, Accuracy = 96.17%: 100%|██████████| 13/13 [00:00<00:00, 63.36it/s]\n","[14 / 50] Train: Loss = 0.00071, Accuracy = 99.97%: 100%|██████████| 572/572 [00:07<00:00, 73.73it/s]\n","[14 / 50]   Val: Loss = 0.04673, Accuracy = 96.18%: 100%|██████████| 13/13 [00:00<00:00, 52.51it/s]\n","[15 / 50] Train: Loss = 0.00046, Accuracy = 99.98%: 100%|██████████| 572/572 [00:07<00:00, 75.73it/s]\n","[15 / 50]   Val: Loss = 0.04668, Accuracy = 96.18%: 100%|██████████| 13/13 [00:00<00:00, 59.59it/s]\n","[16 / 50] Train: Loss = 0.00049, Accuracy = 99.98%: 100%|██████████| 572/572 [00:08<00:00, 68.31it/s]\n","[16 / 50]   Val: Loss = 0.05083, Accuracy = 96.13%: 100%|██████████| 13/13 [00:00<00:00, 57.11it/s]\n","[17 / 50] Train: Loss = 0.00099, Accuracy = 99.92%: 100%|██████████| 572/572 [00:07<00:00, 78.77it/s]\n","[17 / 50]   Val: Loss = 0.05333, Accuracy = 96.09%: 100%|██████████| 13/13 [00:00<00:00, 65.53it/s]\n","[18 / 50] Train: Loss = 0.00064, Accuracy = 99.96%: 100%|██████████| 572/572 [00:07<00:00, 75.61it/s]\n","[18 / 50]   Val: Loss = 0.04880, Accuracy = 96.23%: 100%|██████████| 13/13 [00:00<00:00, 56.57it/s]\n","[19 / 50] Train: Loss = 0.00019, Accuracy = 99.99%: 100%|██████████| 572/572 [00:07<00:00, 78.43it/s]\n","[19 / 50]   Val: Loss = 0.05685, Accuracy = 96.20%: 100%|██████████| 13/13 [00:00<00:00, 65.53it/s]\n","[20 / 50] Train: Loss = 0.00010, Accuracy = 100.00%: 100%|██████████| 572/572 [00:07<00:00, 80.39it/s]\n","[20 / 50]   Val: Loss = 0.05271, Accuracy = 96.27%: 100%|██████████| 13/13 [00:00<00:00, 52.05it/s]\n","[21 / 50] Train: Loss = 0.00005, Accuracy = 100.00%: 100%|██████████| 572/572 [00:07<00:00, 76.63it/s]\n","[21 / 50]   Val: Loss = 0.05561, Accuracy = 96.27%: 100%|██████████| 13/13 [00:00<00:00, 47.01it/s]\n","[22 / 50] Train: Loss = 0.00004, Accuracy = 100.00%: 100%|██████████| 572/572 [00:07<00:00, 77.03it/s]\n","[22 / 50]   Val: Loss = 0.05299, Accuracy = 96.24%: 100%|██████████| 13/13 [00:00<00:00, 55.94it/s]\n","[23 / 50] Train: Loss = 0.00004, Accuracy = 100.00%: 100%|██████████| 572/572 [00:07<00:00, 75.70it/s]\n","[23 / 50]   Val: Loss = 0.05571, Accuracy = 96.26%: 100%|██████████| 13/13 [00:00<00:00, 61.08it/s]\n","[24 / 50] Train: Loss = 0.00196, Accuracy = 99.80%: 100%|██████████| 572/572 [00:07<00:00, 80.26it/s]\n","[24 / 50]   Val: Loss = 0.05793, Accuracy = 95.84%: 100%|██████████| 13/13 [00:00<00:00, 34.81it/s]\n","[25 / 50] Train: Loss = 0.00082, Accuracy = 99.92%: 100%|██████████| 572/572 [00:08<00:00, 67.84it/s]\n","[25 / 50]   Val: Loss = 0.06010, Accuracy = 96.01%: 100%|██████████| 13/13 [00:00<00:00, 64.69it/s]\n","[26 / 50] Train: Loss = 0.00018, Accuracy = 99.99%: 100%|██████████| 572/572 [00:07<00:00, 78.58it/s]\n","[26 / 50]   Val: Loss = 0.05605, Accuracy = 96.06%: 100%|██████████| 13/13 [00:00<00:00, 50.76it/s]\n","[27 / 50] Train: Loss = 0.00006, Accuracy = 100.00%: 100%|██████████| 572/572 [00:07<00:00, 71.95it/s]\n","[27 / 50]   Val: Loss = 0.05888, Accuracy = 96.09%: 100%|██████████| 13/13 [00:00<00:00, 62.46it/s]\n","[28 / 50] Train: Loss = 0.00003, Accuracy = 100.00%: 100%|██████████| 572/572 [00:06<00:00, 83.52it/s]\n","[28 / 50]   Val: Loss = 0.06303, Accuracy = 96.11%: 100%|██████████| 13/13 [00:00<00:00, 57.79it/s]\n","[29 / 50] Train: Loss = 0.00003, Accuracy = 100.00%: 100%|██████████| 572/572 [00:07<00:00, 72.78it/s]\n","[29 / 50]   Val: Loss = 0.05919, Accuracy = 96.11%: 100%|██████████| 13/13 [00:00<00:00, 64.59it/s]\n","[30 / 50] Train: Loss = 0.00003, Accuracy = 100.00%: 100%|██████████| 572/572 [00:06<00:00, 81.93it/s]\n","[30 / 50]   Val: Loss = 0.06186, Accuracy = 96.08%: 100%|██████████| 13/13 [00:00<00:00, 61.86it/s]\n","[31 / 50] Train: Loss = 0.00003, Accuracy = 100.00%: 100%|██████████| 572/572 [00:08<00:00, 70.77it/s]\n","[31 / 50]   Val: Loss = 0.06157, Accuracy = 96.06%: 100%|██████████| 13/13 [00:00<00:00, 63.84it/s]\n","[32 / 50] Train: Loss = 0.00152, Accuracy = 99.84%: 100%|██████████| 572/572 [00:06<00:00, 82.68it/s]\n","[32 / 50]   Val: Loss = 0.06593, Accuracy = 95.90%: 100%|██████████| 13/13 [00:00<00:00, 63.46it/s]\n","[33 / 50] Train: Loss = 0.00050, Accuracy = 99.95%: 100%|██████████| 572/572 [00:07<00:00, 71.57it/s]\n","[33 / 50]   Val: Loss = 0.06783, Accuracy = 95.73%: 100%|██████████| 13/13 [00:00<00:00, 64.89it/s]\n","[34 / 50] Train: Loss = 0.00012, Accuracy = 99.99%: 100%|██████████| 572/572 [00:06<00:00, 83.29it/s]\n","[34 / 50]   Val: Loss = 0.06287, Accuracy = 96.05%: 100%|██████████| 13/13 [00:00<00:00, 62.87it/s]\n","[35 / 50] Train: Loss = 0.00003, Accuracy = 100.00%: 100%|██████████| 572/572 [00:07<00:00, 73.06it/s]\n","[35 / 50]   Val: Loss = 0.06327, Accuracy = 96.05%: 100%|██████████| 13/13 [00:00<00:00, 50.37it/s]\n","[36 / 50] Train: Loss = 0.00002, Accuracy = 100.00%: 100%|██████████| 572/572 [00:06<00:00, 82.53it/s]\n","[36 / 50]   Val: Loss = 0.06736, Accuracy = 96.07%: 100%|██████████| 13/13 [00:00<00:00, 63.09it/s]\n","[37 / 50] Train: Loss = 0.00002, Accuracy = 100.00%: 100%|██████████| 572/572 [00:07<00:00, 73.84it/s]\n","[37 / 50]   Val: Loss = 0.06586, Accuracy = 96.07%: 100%|██████████| 13/13 [00:00<00:00, 54.13it/s]\n","[38 / 50] Train: Loss = 0.00002, Accuracy = 100.00%: 100%|██████████| 572/572 [00:07<00:00, 79.20it/s]\n","[38 / 50]   Val: Loss = 0.07227, Accuracy = 96.07%: 100%|██████████| 13/13 [00:00<00:00, 64.76it/s]\n","[39 / 50] Train: Loss = 0.00001, Accuracy = 100.00%: 100%|██████████| 572/572 [00:08<00:00, 64.62it/s]\n","[39 / 50]   Val: Loss = 0.07188, Accuracy = 96.10%: 100%|██████████| 13/13 [00:00<00:00, 52.87it/s]\n","[40 / 50] Train: Loss = 0.00002, Accuracy = 100.00%: 100%|██████████| 572/572 [00:07<00:00, 79.90it/s]\n","[40 / 50]   Val: Loss = 0.07015, Accuracy = 96.12%: 100%|██████████| 13/13 [00:00<00:00, 59.17it/s]\n","[41 / 50] Train: Loss = 0.00002, Accuracy = 100.00%: 100%|██████████| 572/572 [00:07<00:00, 74.59it/s]\n","[41 / 50]   Val: Loss = 0.07718, Accuracy = 96.09%: 100%|██████████| 13/13 [00:00<00:00, 61.47it/s]\n","[42 / 50] Train: Loss = 0.00147, Accuracy = 99.86%: 100%|██████████| 572/572 [00:07<00:00, 78.85it/s]\n","[42 / 50]   Val: Loss = 0.06670, Accuracy = 95.93%: 100%|██████████| 13/13 [00:00<00:00, 62.80it/s]\n","[43 / 50] Train: Loss = 0.00074, Accuracy = 99.92%: 100%|██████████| 572/572 [00:07<00:00, 76.97it/s]\n","[43 / 50]   Val: Loss = 0.06504, Accuracy = 96.07%: 100%|██████████| 13/13 [00:00<00:00, 51.48it/s]\n","[44 / 50] Train: Loss = 0.00013, Accuracy = 99.99%: 100%|██████████| 572/572 [00:07<00:00, 75.35it/s]\n","[44 / 50]   Val: Loss = 0.06513, Accuracy = 96.13%: 100%|██████████| 13/13 [00:00<00:00, 63.11it/s]\n","[45 / 50] Train: Loss = 0.00003, Accuracy = 100.00%: 100%|██████████| 572/572 [00:07<00:00, 78.23it/s]\n","[45 / 50]   Val: Loss = 0.06877, Accuracy = 96.14%: 100%|██████████| 13/13 [00:00<00:00, 58.17it/s]\n","[46 / 50] Train: Loss = 0.00002, Accuracy = 100.00%: 100%|██████████| 572/572 [00:07<00:00, 73.85it/s]\n","[46 / 50]   Val: Loss = 0.06908, Accuracy = 96.16%: 100%|██████████| 13/13 [00:00<00:00, 56.68it/s]\n","[47 / 50] Train: Loss = 0.00002, Accuracy = 100.00%: 100%|██████████| 572/572 [00:07<00:00, 79.36it/s]\n","[47 / 50]   Val: Loss = 0.07220, Accuracy = 96.17%: 100%|██████████| 13/13 [00:00<00:00, 62.25it/s]\n","[48 / 50] Train: Loss = 0.00001, Accuracy = 100.00%: 100%|██████████| 572/572 [00:07<00:00, 72.89it/s]\n","[48 / 50]   Val: Loss = 0.06737, Accuracy = 96.18%: 100%|██████████| 13/13 [00:00<00:00, 64.22it/s]\n","[49 / 50] Train: Loss = 0.00002, Accuracy = 100.00%: 100%|██████████| 572/572 [00:07<00:00, 80.45it/s]\n","[49 / 50]   Val: Loss = 0.07054, Accuracy = 96.16%: 100%|██████████| 13/13 [00:00<00:00, 57.67it/s]\n","[50 / 50] Train: Loss = 0.00001, Accuracy = 100.00%: 100%|██████████| 572/572 [00:07<00:00, 73.08it/s]\n","[50 / 50]   Val: Loss = 0.07823, Accuracy = 96.18%: 100%|██████████| 13/13 [00:00<00:00, 63.65it/s]\n"]}]},{"cell_type":"code","source":["evaluate_model(model, data=(X_test, y_test), batch_size=512)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aK8cu59H6twh","executionInfo":{"status":"ok","timestamp":1683525574101,"user_tz":-420,"elapsed":581,"user":{"displayName":"Елизавета Егоровна Пришляк","userId":"17629377755238160682"}},"outputId":"01ce5c7e-3b17-412a-d125-d98ea4247fcc"},"execution_count":54,"outputs":[{"output_type":"stream","name":"stderr","text":["      Loss = 0.07883, Accuracy = 96.17%: 100%|██████████| 28/28 [00:00<00:00, 66.17it/s]\n"]}]},{"cell_type":"markdown","metadata":{"id":"ZTXmYGD_ANhm"},"source":["### Предобученные эмбеддинги\n","\n","Мы знаем, какая клёвая вещь - предобученные эмбеддинги. При текущем размере обучающей выборки еще можно было учить их и с нуля - с меньшей было бы совсем плохо.\n","\n","Поэтому стандартный пайплайн - скачать эмбеддинги, засунуть их в сеточку. Запустим его:"]},{"cell_type":"code","execution_count":70,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uZpY_Q1xZ18h","executionInfo":{"status":"ok","timestamp":1683528709602,"user_tz":-420,"elapsed":62160,"user":{"displayName":"Елизавета Егоровна Пришляк","userId":"17629377755238160682"}},"outputId":"9329a337-6376-4da8-d83b-425af8be3850"},"outputs":[{"output_type":"stream","name":"stdout","text":["[==================================================] 100.0% 128.1/128.1MB downloaded\n"]}],"source":["import gensim.downloader as api\n","\n","w2v_model = api.load('glove-wiki-gigaword-100')"]},{"cell_type":"markdown","metadata":{"id":"KYogOoKlgtcf"},"source":["Построим подматрицу для слов из нашей тренировочной выборки:"]},{"cell_type":"code","execution_count":71,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VsCstxiO03oT","executionInfo":{"status":"ok","timestamp":1683528740843,"user_tz":-420,"elapsed":962,"user":{"displayName":"Елизавета Егоровна Пришляк","userId":"17629377755238160682"}},"outputId":"0cefcb11-6b7e-45e1-abfe-f6200db9c328"},"outputs":[{"output_type":"stream","name":"stdout","text":["Know 38736 out of 45441 word embeddings\n"]}],"source":["known_count = 0\n","embeddings = np.zeros((len(word2ind), w2v_model.vectors.shape[1]))\n","for word, ind in word2ind.items():\n","    word = word.lower()\n","    if word in w2v_model.vocab:\n","        embeddings[ind] = w2v_model.get_vector(word)\n","        known_count += 1\n","        \n","print('Know {} out of {} word embeddings'.format(known_count, len(word2ind)))"]},{"cell_type":"markdown","metadata":{"id":"HcG7i-R8hbY3"},"source":["**Задание** Сделайте модель с предобученной матрицей. Используйте `nn.Embedding.from_pretrained`."]},{"cell_type":"code","execution_count":91,"metadata":{"id":"LxaRBpQd0pat","executionInfo":{"status":"ok","timestamp":1683530817894,"user_tz":-420,"elapsed":2,"user":{"displayName":"Елизавета Егоровна Пришляк","userId":"17629377755238160682"}}},"outputs":[],"source":["class LSTMTaggerWithPretrainedEmbs(nn.Module):\n","    def __init__(self, embeddings, tagset_size, lstm_hidden_dim=64, lstm_layers_count=1):\n","        super().__init__()\n","        self.embedding =nn.Embedding.from_pretrained(torch.FloatTensor(embeddings))\n","        self.lstm = nn.LSTM(embeddings.shape[1], lstm_hidden_dim, lstm_layers_count, bidirectional=False)\n","        self.fully_connected = nn.Linear(lstm_hidden_dim, tagset_size)\n","\n","    def forward(self, inputs):\n","        embedded_in = self.embedding(inputs)\n","        lstm_out, _ = self.lstm(embedded_in)\n","        return self.fully_connected(lstm_out)"]},{"cell_type":"code","execution_count":98,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EBtI6BDE-Fc7","executionInfo":{"status":"ok","timestamp":1683533948931,"user_tz":-420,"elapsed":123882,"user":{"displayName":"Елизавета Егоровна Пришляк","userId":"17629377755238160682"}},"outputId":"dde32127-94f1-4ad8-def2-a3db20e6f734"},"outputs":[{"output_type":"stream","name":"stderr","text":["[1 / 25] Train: Loss = 0.75835, Accuracy = 77.46%: 100%|██████████| 572/572 [00:04<00:00, 133.73it/s]\n","[1 / 25]   Val: Loss = 0.36837, Accuracy = 89.24%: 100%|██████████| 26/26 [00:00<00:00, 134.41it/s]\n","[2 / 25] Train: Loss = 0.28403, Accuracy = 91.42%: 100%|██████████| 572/572 [00:04<00:00, 114.46it/s]\n","[2 / 25]   Val: Loss = 0.25830, Accuracy = 91.99%: 100%|██████████| 26/26 [00:00<00:00, 132.00it/s]\n","[3 / 25] Train: Loss = 0.20916, Accuracy = 93.43%: 100%|██████████| 572/572 [00:05<00:00, 110.08it/s]\n","[3 / 25]   Val: Loss = 0.20794, Accuracy = 93.36%: 100%|██████████| 26/26 [00:00<00:00, 135.34it/s]\n","[4 / 25] Train: Loss = 0.17195, Accuracy = 94.49%: 100%|██████████| 572/572 [00:04<00:00, 135.57it/s]\n","[4 / 25]   Val: Loss = 0.18287, Accuracy = 94.13%: 100%|██████████| 26/26 [00:00<00:00, 136.54it/s]\n","[5 / 25] Train: Loss = 0.15048, Accuracy = 95.12%: 100%|██████████| 572/572 [00:04<00:00, 133.55it/s]\n","[5 / 25]   Val: Loss = 0.16995, Accuracy = 94.55%: 100%|██████████| 26/26 [00:00<00:00, 118.10it/s]\n","[6 / 25] Train: Loss = 0.13671, Accuracy = 95.48%: 100%|██████████| 572/572 [00:05<00:00, 106.46it/s]\n","[6 / 25]   Val: Loss = 0.16018, Accuracy = 94.71%: 100%|██████████| 26/26 [00:00<00:00, 93.61it/s]\n","[7 / 25] Train: Loss = 0.12710, Accuracy = 95.75%: 100%|██████████| 572/572 [00:04<00:00, 130.93it/s]\n","[7 / 25]   Val: Loss = 0.15380, Accuracy = 94.81%: 100%|██████████| 26/26 [00:00<00:00, 148.11it/s]\n","[8 / 25] Train: Loss = 0.12024, Accuracy = 95.94%: 100%|██████████| 572/572 [00:04<00:00, 134.56it/s]\n","[8 / 25]   Val: Loss = 0.14783, Accuracy = 95.05%: 100%|██████████| 26/26 [00:00<00:00, 136.65it/s]\n","[9 / 25] Train: Loss = 0.11451, Accuracy = 96.11%: 100%|██████████| 572/572 [00:05<00:00, 112.25it/s]\n","[9 / 25]   Val: Loss = 0.14608, Accuracy = 95.02%: 100%|██████████| 26/26 [00:00<00:00, 110.90it/s]\n","[10 / 25] Train: Loss = 0.11006, Accuracy = 96.24%: 100%|██████████| 572/572 [00:04<00:00, 118.10it/s]\n","[10 / 25]   Val: Loss = 0.14348, Accuracy = 95.19%: 100%|██████████| 26/26 [00:00<00:00, 132.21it/s]\n","[11 / 25] Train: Loss = 0.10617, Accuracy = 96.34%: 100%|██████████| 572/572 [00:04<00:00, 131.04it/s]\n","[11 / 25]   Val: Loss = 0.14069, Accuracy = 95.27%: 100%|██████████| 26/26 [00:00<00:00, 129.29it/s]\n","[12 / 25] Train: Loss = 0.10293, Accuracy = 96.44%: 100%|██████████| 572/572 [00:04<00:00, 120.84it/s]\n","[12 / 25]   Val: Loss = 0.13912, Accuracy = 95.16%: 100%|██████████| 26/26 [00:00<00:00, 114.66it/s]\n","[13 / 25] Train: Loss = 0.10028, Accuracy = 96.52%: 100%|██████████| 572/572 [00:05<00:00, 108.21it/s]\n","[13 / 25]   Val: Loss = 0.13797, Accuracy = 95.23%: 100%|██████████| 26/26 [00:00<00:00, 132.31it/s]\n","[14 / 25] Train: Loss = 0.09755, Accuracy = 96.60%: 100%|██████████| 572/572 [00:04<00:00, 132.86it/s]\n","[14 / 25]   Val: Loss = 0.13769, Accuracy = 95.21%: 100%|██████████| 26/26 [00:00<00:00, 140.76it/s]\n","[15 / 25] Train: Loss = 0.09568, Accuracy = 96.68%: 100%|██████████| 572/572 [00:04<00:00, 130.82it/s]\n","[15 / 25]   Val: Loss = 0.13661, Accuracy = 95.36%: 100%|██████████| 26/26 [00:00<00:00, 135.22it/s]\n","[16 / 25] Train: Loss = 0.09357, Accuracy = 96.73%: 100%|██████████| 572/572 [00:05<00:00, 104.48it/s]\n","[16 / 25]   Val: Loss = 0.13508, Accuracy = 95.30%: 100%|██████████| 26/26 [00:00<00:00, 110.60it/s]\n","[17 / 25] Train: Loss = 0.09174, Accuracy = 96.78%: 100%|██████████| 572/572 [00:04<00:00, 124.00it/s]\n","[17 / 25]   Val: Loss = 0.13368, Accuracy = 95.45%: 100%|██████████| 26/26 [00:00<00:00, 128.44it/s]\n","[18 / 25] Train: Loss = 0.09002, Accuracy = 96.83%: 100%|██████████| 572/572 [00:04<00:00, 131.86it/s]\n","[18 / 25]   Val: Loss = 0.13610, Accuracy = 95.33%: 100%|██████████| 26/26 [00:00<00:00, 134.52it/s]\n","[19 / 25] Train: Loss = 0.08844, Accuracy = 96.87%: 100%|██████████| 572/572 [00:05<00:00, 112.43it/s]\n","[19 / 25]   Val: Loss = 0.13377, Accuracy = 95.34%: 100%|██████████| 26/26 [00:00<00:00, 110.26it/s]\n","[20 / 25] Train: Loss = 0.08698, Accuracy = 96.93%: 100%|██████████| 572/572 [00:04<00:00, 115.33it/s]\n","[20 / 25]   Val: Loss = 0.13591, Accuracy = 95.46%: 100%|██████████| 26/26 [00:00<00:00, 134.59it/s]\n","[21 / 25] Train: Loss = 0.08565, Accuracy = 96.97%: 100%|██████████| 572/572 [00:04<00:00, 128.49it/s]\n","[21 / 25]   Val: Loss = 0.13579, Accuracy = 95.33%: 100%|██████████| 26/26 [00:00<00:00, 133.91it/s]\n","[22 / 25] Train: Loss = 0.08439, Accuracy = 97.01%: 100%|██████████| 572/572 [00:04<00:00, 119.44it/s]\n","[22 / 25]   Val: Loss = 0.13337, Accuracy = 95.30%: 100%|██████████| 26/26 [00:00<00:00, 106.29it/s]\n","[23 / 25] Train: Loss = 0.08330, Accuracy = 97.04%: 100%|██████████| 572/572 [00:05<00:00, 108.33it/s]\n","[23 / 25]   Val: Loss = 0.13520, Accuracy = 95.33%: 100%|██████████| 26/26 [00:00<00:00, 134.53it/s]\n","[24 / 25] Train: Loss = 0.08216, Accuracy = 97.08%: 100%|██████████| 572/572 [00:04<00:00, 126.53it/s]\n","[24 / 25]   Val: Loss = 0.13353, Accuracy = 95.45%: 100%|██████████| 26/26 [00:00<00:00, 131.26it/s]\n","[25 / 25] Train: Loss = 0.08101, Accuracy = 97.12%: 100%|██████████| 572/572 [00:04<00:00, 124.14it/s]\n","[25 / 25]   Val: Loss = 0.13353, Accuracy = 95.33%: 100%|██████████| 26/26 [00:00<00:00, 128.77it/s]\n"]}],"source":["model = LSTMTaggerWithPretrainedEmbs(\n","    embeddings=embeddings,\n","    tagset_size=len(tag2ind)\n",").cuda()\n","\n","criterion = nn.CrossEntropyLoss(ignore_index=0)\n","optimizer = optim.Adam(model.parameters())\n","\n","fit(model, criterion, optimizer, train_data=(X_train, y_train), epochs_count=25,\n","    batch_size=64, val_data=(X_val, y_val), val_batch_size=256)"]},{"cell_type":"markdown","metadata":{"id":"2Ne_8f24h8kg"},"source":["**Задание** Оцените качество модели на тестовой выборке. Обратите внимание, вовсе не обязательно ограничиваться векторами из урезанной матрицы - вполне могут найтись слова в тесте, которых не было в трейне и для которых есть эмбеддинги.\n","\n","Добейтесь качества лучше прошлых моделей."]},{"cell_type":"code","execution_count":99,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HPUuAPGhEGVR","executionInfo":{"status":"ok","timestamp":1683533949371,"user_tz":-420,"elapsed":457,"user":{"displayName":"Елизавета Егоровна Пришляк","userId":"17629377755238160682"}},"outputId":"0bd5cb6e-7fc1-4b43-80eb-d01d043f1783"},"outputs":[{"output_type":"stream","name":"stderr","text":["      Loss = 0.13345, Accuracy = 95.41%: 100%|██████████| 56/56 [00:00<00:00, 132.47it/s]\n"]}],"source":["evaluate_model(model, data=(X_test, y_test), batch_size=256)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"}},"nbformat":4,"nbformat_minor":0}